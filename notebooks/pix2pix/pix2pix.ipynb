{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "from molanet.models.cgan_pix2pix import Pix2PixModel\n",
    "from molanet.models.cgan_pix2pix import IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image(name: str, source_dir, target_dir, size=IMAGE_SIZE):\n",
    "    def transformImageNameSource(name):\n",
    "        return os.path.join(source_dir, name)\n",
    "\n",
    "    def transformImageNameTarget(name: str):\n",
    "        name = name.replace('.jpg', '_Segmentation.png')\n",
    "        return os.path.join(target_dir, name)\n",
    "\n",
    "    source_image = Image.open(transformImageNameSource(name))\n",
    "    target_image = Image.open(transformImageNameTarget(name))\n",
    "\n",
    "    # TODO think about proper resizing... is dis hacky? I don't know\n",
    "    size = size, size\n",
    "    source = source_image.resize(size, Image.BICUBIC)\n",
    "    target = target_image.resize(size, Image.NEAREST)\n",
    "    target = target.convert('1')  # to black and white\n",
    "\n",
    "    return np.array(source).astype(np.float32), np.array(target).astype(np.float32)\n",
    "\n",
    "\n",
    "def get_image_batch(batch_size, source_file_names, source_dir, target_dir) -> [np.ndarray, np.ndarray]:\n",
    "    # TODO chances are we don't get fucked by rng\n",
    "    indices = [random.randint(0, len(source_file_names) - 1) for _ in range(batch_size)]\n",
    "    images = [load_image(source_file_names[i], source_dir, target_dir) for i in indices]\n",
    "    return images\n",
    "\n",
    "def save_ndarrays_asimage(filename: str, *arrays: np.ndarray):\n",
    "    def fix_dimensions(array):\n",
    "        if array.ndim > 3 or array.ndim < 2: raise ValueError('arrays must have 2 or 3 dimensions')\n",
    "        if array.ndim == 2:\n",
    "            array = np.repeat(array[:, :, np.newaxis], 3, axis=2)  # go from blackwhite to rgb to make concat work seamless\n",
    "        return array\n",
    "\n",
    "    if len(arrays) > 1:\n",
    "        arrays = [fix_dimensions(array) for array in arrays]\n",
    "        arrays = np.concatenate(arrays, axis=1)\n",
    "\n",
    "    # arrays is just a big 3-dim matrix\n",
    "    im = Image.fromarray(np.uint8(arrays))\n",
    "    im.save(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(sess, saver, checkpoint_dir, step):\n",
    "    model_name = \"cgan_pix2pix.model\"\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    saver.save(sess, os.path.join(checkpoint_dir, model_name), global_step=step)\n",
    "\n",
    "\n",
    "def sample_model(filenames: [str], epoch: int, sess: tf.Session, source_dir: str, target_dir: str, model: Pix2PixModel,\n",
    "                 sample_dir: str, rng: bool):\n",
    "    batch = None\n",
    "    if rng:\n",
    "        batch = get_image_batch(1, filenames, source_dir, target_dir)\n",
    "    else:\n",
    "        batch = [load_image('ISIC_0000000.jpg', source_dir, target_dir)]\n",
    "\n",
    "    (batch_src, batch_target) = batch[0]\n",
    "    original_source = batch_src.copy()\n",
    "    original_target = batch_target.copy()\n",
    "    batch_src = (batch_src / 255.0 - 0.5) * 2.0  # Transform into range -1, 1\n",
    "    batch_target = (batch_target - 0.5) * 2.0  # Transform into range -1, 1\n",
    "    batch_src = np.array(batch_src).astype(np.float32)[None, :, :, :]\n",
    "    batch_target = np.array(batch_target).astype(np.float32)[None, :, :, None]\n",
    "\n",
    "    sample, d_loss, g_loss = sess.run(\n",
    "        [model.fake_B, model.d_loss, model.g_loss],\n",
    "        feed_dict={model.real_data_source: batch_src,\n",
    "                   model.real_data_target: batch_target}\n",
    "    )\n",
    "\n",
    "    # convert images from [-1,1] to [0,255]\n",
    "    # from shape [1,255,255,1] : tensor to shape [255,255] : nddarray\n",
    "    sample = (tf.squeeze(sample).eval() + 1.0) / 2.0 * 255\n",
    "\n",
    "    save_ndarrays_asimage(os.path.join(sample_dir, 'sample_%d.png' % epoch), original_source, sample,\n",
    "                          original_target * 255)\n",
    "    print(\"[Sample] d_loss: {:.8f}, g_loss: {:.8f}\".format(d_loss, g_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] time: 2.6624, d_loss: 1.27340591, g_loss: 80.57321930\n",
      "Epoch: [ 1] time: 4.4910, d_loss: 1.24476981, g_loss: 68.81803894\n",
      "[Sample] d_loss: 1.34016788, g_loss: 83.08406067\n",
      "Epoch: [ 2] time: 6.7096, d_loss: 1.23761463, g_loss: 75.75146484\n",
      "Epoch: [ 3] time: 13.8732, d_loss: 1.19189429, g_loss: 55.66500854\n",
      "Epoch: [ 4] time: 15.2937, d_loss: 1.23487878, g_loss: 110.95969391\n",
      "Epoch: [ 5] time: 16.7402, d_loss: 1.18900681, g_loss: 53.89413834\n",
      "Epoch: [ 6] time: 18.1933, d_loss: 1.15724802, g_loss: 44.24517059\n",
      "Epoch: [ 7] time: 19.6368, d_loss: 1.00687110, g_loss: 48.12762070\n",
      "Epoch: [ 8] time: 21.1154, d_loss: 1.18261313, g_loss: 36.72450638\n",
      "Epoch: [ 9] time: 22.5744, d_loss: 1.20217788, g_loss: 36.25959778\n",
      "Epoch: [10] time: 24.1660, d_loss: 1.15379691, g_loss: 37.27838135\n",
      "Epoch: [11] time: 26.2300, d_loss: 1.09702504, g_loss: 47.51559830\n",
      "Epoch: [12] time: 27.7366, d_loss: 1.21805453, g_loss: 24.23547554\n",
      "Epoch: [13] time: 29.1941, d_loss: 1.04359984, g_loss: 38.02343369\n",
      "Epoch: [14] time: 30.6632, d_loss: 1.19453394, g_loss: 24.78600311\n",
      "Epoch: [15] time: 32.2907, d_loss: 0.90025437, g_loss: 31.73887634\n",
      "Epoch: [16] time: 34.0365, d_loss: 1.01041639, g_loss: 61.38429260\n",
      "Epoch: [17] time: 35.5420, d_loss: 1.43654394, g_loss: 25.19441032\n",
      "Epoch: [18] time: 37.0391, d_loss: 2.62401366, g_loss: 16.76826096\n",
      "Epoch: [19] time: 38.5602, d_loss: 1.66940093, g_loss: 25.11582565\n",
      "Epoch: [20] time: 40.3590, d_loss: 1.35108066, g_loss: 27.06496048\n",
      "Epoch: [21] time: 41.8440, d_loss: 1.16488636, g_loss: 48.12831497\n",
      "Epoch: [22] time: 43.3126, d_loss: 1.30078578, g_loss: 18.41569138\n",
      "Epoch: [23] time: 45.3519, d_loss: 1.26493168, g_loss: 22.87187004\n",
      "Epoch: [24] time: 46.9685, d_loss: 1.12626410, g_loss: 39.04320526\n",
      "Epoch: [25] time: 48.8239, d_loss: 1.23416317, g_loss: 24.33195496\n",
      "Epoch: [26] time: 50.6302, d_loss: 1.23712778, g_loss: 14.95542336\n",
      "Epoch: [27] time: 52.7697, d_loss: 1.32617486, g_loss: 17.97362709\n",
      "Epoch: [28] time: 54.5453, d_loss: 1.38008463, g_loss: 14.83681488\n",
      "Epoch: [29] time: 56.1946, d_loss: 0.82034975, g_loss: 90.63428497\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-1254f4b3c8fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m         _, summary_str = sess.run([gen_update_step, g_sum],\n\u001b[0;32m     75\u001b[0m                                   feed_dict={model.real_data_source: batch_src,\n\u001b[1;32m---> 76\u001b[1;33m                                              model.real_data_target: batch_target})\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "source_dir = r'../../../pix2pix-poc-data/training/source'\n",
    "target_dir = r'../../../pix2pix-poc-data/training/target'\n",
    "sourcefiles = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "sample_dir = \"./samples/sample-%d-%d-%d--%02d%02d\" % (\n",
    "    now.day, now.month, now.year, now.hour, now.minute)  # Generated samples\n",
    "checkpoint_dir = \"./checkpoints\"  # Model\n",
    "if not os.path.exists('./samples'):\n",
    "    os.mkdir('./samples')\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.mkdir(sample_dir)\n",
    "\n",
    "use_random_image_as_sample = False\n",
    "batch_size = 1\n",
    "size = IMAGE_SIZE\n",
    "num_feature_maps = 64\n",
    "is_grayscale = False\n",
    "\n",
    "restore_iteration = None\n",
    "iterations = 50000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model = Pix2PixModel(batch_size=batch_size, image_size=size, src_color_channels=3, target_color_channels=1)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    if restore_iteration is not None and restore_iteration > 0:\n",
    "        iteration_start = restore_iteration + 1\n",
    "        checkpoint = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        checkpoint_name = os.path.basename(checkpoint.model_checkpoint_path)\n",
    "        print('checkpoint_name=' + str(checkpoint_name))\n",
    "        saver.restore(sess, os.path.join(checkpoint_dir, checkpoint_name))\n",
    "    else:\n",
    "        iteration_start = 0\n",
    "\n",
    "    # Optimizers\n",
    "    disc_optim = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5)  # TODO: pix2pix params\n",
    "    gen_optim = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5)  # TODO: pix2pix params\n",
    "\n",
    "    disc_update_step = disc_optim.minimize(model.d_loss, var_list=model.d_vars)\n",
    "    gen_update_step = gen_optim.minimize(model.g_loss, var_list=model.g_vars)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # logging\n",
    "    writer = tf.summary.FileWriter(\"./logs\", sess.graph)\n",
    "    g_sum = tf.summary.merge([model.d__sum,\n",
    "                              model.fake_B_sum, model.d_loss_fake_sum, model.g_loss_sum])\n",
    "    d_sum = tf.summary.merge([model.d_sum, model.d_loss_real_sum, model.d_loss_sum])\n",
    "\n",
    "    start_time = time.time()\n",
    "    for iteration in range(iteration_start, iterations):\n",
    "        batch = get_image_batch(batch_size, sourcefiles,\n",
    "                                source_dir=source_dir,\n",
    "                                target_dir=target_dir)\n",
    "        (batch_src, batch_target) = batch[0]\n",
    "        batch_src = (batch_src / 255.0 - 0.5) * 2.0  # Transform into range -1, 1\n",
    "        batch_target = (batch_target - 0.5) * 2.0  # Transform into range -1, 1\n",
    "\n",
    "        batch_src = np.array(batch_src).astype(np.float32)[None, :, :, :]\n",
    "        batch_target = np.array(batch_target).astype(np.float32)[None, :, :, None]\n",
    "\n",
    "        _, summary_str = sess.run([disc_update_step, d_sum],\n",
    "                                  feed_dict={model.real_data_source: batch_src,\n",
    "                                             model.real_data_target: batch_target})\n",
    "\n",
    "        writer.add_summary(summary_str, iteration)\n",
    "\n",
    "        # Update G network twice\n",
    "        _, summary_str = sess.run([gen_update_step, g_sum],\n",
    "                                  feed_dict={model.real_data_source: batch_src,\n",
    "                                             model.real_data_target: batch_target})\n",
    "        writer.add_summary(summary_str, iteration)\n",
    "        _, summary_str = sess.run([gen_update_step, g_sum],\n",
    "                                  feed_dict={model.real_data_source: batch_src,\n",
    "                                             model.real_data_target: batch_target})\n",
    "        writer.add_summary(summary_str, iteration)\n",
    "\n",
    "        errD_fake = model.d_loss_fake.eval(\n",
    "            {model.real_data_target: batch_target, model.real_data_source: batch_src})\n",
    "        errD_real = model.d_loss_real.eval(\n",
    "            {model.real_data_target: batch_target, model.real_data_source: batch_src})\n",
    "        errG = model.g_loss.eval({model.real_data_target: batch_target, model.real_data_source: batch_src})\n",
    "\n",
    "        print(\"Epoch: [%2d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n",
    "              % (iteration, time.time() - start_time, errD_fake + errD_real, errG))\n",
    "\n",
    "        if iteration % 50 == 1:\n",
    "            # gib nice picture output :)\n",
    "            sample_model(sourcefiles, iteration, sess, source_dir, target_dir, model, sample_dir,\n",
    "                         use_random_image_as_sample)\n",
    "\n",
    "        if iteration % 500 == 2:\n",
    "            save(sess, saver, checkpoint_dir, iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python",
   "language": "python",
   "name": ".python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
