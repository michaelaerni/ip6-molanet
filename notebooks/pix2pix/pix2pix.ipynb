{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "random.seed(12435345)\n",
    "import sys\n",
    "import time\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "from molanet.models.cgan_pix2pix import Pix2PixModel\n",
    "from molanet.models.cgan_pix2pix import IMAGE_SIZE\n",
    "from molanet.poc_utils import load_image,get_image_batch,transform_batch,save_ndarrays_asimage,save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_model(filenames: [str], batch_size: int, epoch: int, sess: tf.Session, source_dir: str, target_dir: str,\n",
    "                 model: Pix2PixModel,\n",
    "                 sample_dir: str, max_samples: int = 3):\n",
    "    nsamples = min(batch_size, max_samples)\n",
    "\n",
    "    batch = get_image_batch(batch_size, filenames, source_dir, target_dir)\n",
    "    batch_src, batch_target = transform_batch(batch)\n",
    "\n",
    "    sample, d_loss, g_loss = sess.run(\n",
    "        [model.fake_B, model.d_loss, model.g_loss],\n",
    "        feed_dict={model.real_data_source: batch_src,\n",
    "                   model.real_data_target: batch_target}\n",
    "    )\n",
    "\n",
    "    size = sample.shape[2]\n",
    "    zdim = batch_src.shape[-1]\n",
    "\n",
    "    sample = tf.squeeze(sample).eval()[:nsamples]\n",
    "    batch_src = batch_src[:nsamples]\n",
    "    batch_target = batch_target[:nsamples]\n",
    "\n",
    "    # from shape [nsamples,size,size,1] : tf.tensor to shape [size*nsamples,size] : ndarray\n",
    "    sample = (np.reshape(sample, [size * nsamples, size]) + 1.0) / 2.0 * 255\n",
    "    original_source = (tf.reshape(batch_src, [size * nsamples, size, zdim]).eval() + 1.0) / 2.0 * 255\n",
    "    original_target = (tf.reshape(tf.squeeze(batch_target), [size * nsamples, size]).eval() + 1.0) / 2.0 * 255\n",
    "    sample_error = np.absolute(original_target - sample)\n",
    "\n",
    "    save_ndarrays_asimage(os.path.join(sample_dir, 'sample_%d.png' % epoch), original_source, sample,\n",
    "                          original_target, sample_error)\n",
    "    print(\"[Sample] d_loss: {:.8f}, g_loss: {:.8f}\".format(d_loss, g_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "source_dir = r'../../../pix2pix-poc-data/training/source'\n",
    "target_dir = r'../../../pix2pix-poc-data/training/target'\n",
    "sourcefiles = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "sample_dir = \"./samples/sample-%d-%d-%d--%02d%02d\" % (\n",
    "    now.day, now.month, now.year, now.hour, now.minute)  # Generated samples\n",
    "checkpoint_dir = \"../logs/pix2pix\"  # Model\n",
    "if not os.path.exists('./samples'):\n",
    "    os.mkdir('./samples')\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.mkdir(sample_dir)\n",
    "\n",
    "#Parameters\n",
    "batch_size = 5\n",
    "size = IMAGE_SIZE\n",
    "num_feature_maps = 64 #feature maps on first conv layer\n",
    "L1_lambda_generator = 100\n",
    "iterations = 50000\n",
    "d_updates = 1 #number of training sessions for discriminator per iteration\n",
    "g_updates = 1 # generator training sessions\n",
    "d_learning_rate = 0.0002\n",
    "g_learning_rate = 0.0002\n",
    "d_beta1 = 0.5\n",
    "g_beta1 = 0.5\n",
    "\n",
    "#non-learning related config\n",
    "restore_iteration = None\n",
    "use_random_image_as_sample = True\n",
    "max_samples = 5\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model = Pix2PixModel(batch_size=batch_size, \n",
    "                        image_size=size, \n",
    "                        src_color_channels=3, \n",
    "                        target_color_channels=1,\n",
    "                        g_l1_lambda=L1_lambda_generator)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    if restore_iteration is not None and restore_iteration > 0:\n",
    "        iration_start = restore_iteration + 1\n",
    "        checkpoint = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        checkpoint_name = os.path.basename(checkpoint.model_checkpoint_path)\n",
    "        print('checkpoint_name=' + str(checkpoint_name))\n",
    "        saver.restore(sess, os.path.join(checkpoint_dir, checkpoint_name))\n",
    "    else:\n",
    "        iteration_start = 0\n",
    "\n",
    "    # Optimizers\n",
    "    disc_optim = tf.train.AdamOptimizer(learning_rate=d_learning_rate, beta1=d_beta1)\n",
    "    gen_optim = tf.train.AdamOptimizer(learning_rate=d_learning_rate, beta1=g_beta1)\n",
    "\n",
    "    disc_update_step = disc_optim.minimize(model.d_loss, var_list=model.d_vars)\n",
    "    gen_update_step = gen_optim.minimize(model.g_loss, var_list=model.g_vars)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # logging\n",
    "    writer = tf.summary.FileWriter(checkpoint_dir, sess.graph)\n",
    "    g_sum = tf.summary.merge([model.d__sum,\n",
    "                              model.d_loss_fake_sum, \n",
    "                              model.g_loss_sum, \n",
    "                              model.image_sum])\n",
    "    \n",
    "    d_sum = tf.summary.merge([model.d_sum, model.d_loss_real_sum, model.d_loss_sum])\n",
    "\n",
    "    start_time = time.time()\n",
    "    for iteration in range(iteration_start, iterations):\n",
    "        batch = get_image_batch(batch_size, sourcefiles,\n",
    "                                source_dir=source_dir,\n",
    "                                target_dir=target_dir)\n",
    "        batch_src,batch_target = transform_batch(batch)\n",
    "\n",
    "        #as proposed in glsgan paper update discriminator N time every iteration\n",
    "        for i in range(0,d_updates):\n",
    "            _, summary_str = sess.run([disc_update_step, d_sum],\n",
    "                                      feed_dict={model.real_data_source: batch_src,\n",
    "                                                 model.real_data_target: batch_target})\n",
    "            writer.add_summary(summary_str, iteration)\n",
    "\n",
    "        # Update G network\n",
    "        for i in range(0,g_updates):\n",
    "            _, summary_str = sess.run([gen_update_step, g_sum],\n",
    "                                  feed_dict={model.real_data_source: batch_src,\n",
    "                                             model.real_data_target: batch_target})\n",
    "            writer.add_summary(summary_str, iteration)\n",
    "\n",
    "        #if iteration % 50 == 1:\n",
    "            # gib nice picture output :) output directly to tensorboard\n",
    "            #sample_model(sourcefiles, batch_size, iteration, sess, source_dir, target_dir, model, sample_dir,\n",
    "             #            max_samples=max_samples)\n",
    "\n",
    "        if iteration % 500 == 2:\n",
    "            save(sess, saver, checkpoint_dir, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (whatever you want to call it)",
   "language": "python",
   "name": "envname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
