{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "from molanet.models.glsgan import Pix2PixModel\n",
    "from molanet.models.glsgan import IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Image Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_image(name: str, source_dir, target_dir, size=IMAGE_SIZE):\n",
    "    def transformImageNameSource(name):\n",
    "        return os.path.join(source_dir, name)\n",
    "\n",
    "    def transformImageNameTarget(name: str):\n",
    "        name = name.replace('.jpg', '_Segmentation.png')\n",
    "        return os.path.join(target_dir, name)\n",
    "\n",
    "    source_image = Image.open(transformImageNameSource(name))\n",
    "    target_image = Image.open(transformImageNameTarget(name))\n",
    "\n",
    "    # TODO think about proper resizing... is dis hacky? I don't know\n",
    "    size = size, size\n",
    "    source = source_image.resize(size, Image.BICUBIC)\n",
    "    target = target_image.resize(size, Image.NEAREST)\n",
    "    target = target.convert('1')  # to black and white\n",
    "\n",
    "    return np.array(source).astype(np.float32), np.array(target).astype(np.float32)\n",
    "\n",
    "\n",
    "def get_image_batch(batch_size, source_file_names, source_dir, target_dir) -> [np.ndarray, np.ndarray]:\n",
    "    # TODO chances are we don't get fucked by rng\n",
    "    indices = [random.randint(0, len(source_file_names) - 1) for _ in range(batch_size)]\n",
    "    images = [load_image(source_file_names[i], source_dir, target_dir) for i in indices]\n",
    "    return images\n",
    "\n",
    "def save_ndarrays_asimage(filename: str, *arrays: np.ndarray):\n",
    "    def fix_dimensions(array):\n",
    "        if array.ndim > 3 or array.ndim < 2: raise ValueError('arrays must have 2 or 3 dimensions')\n",
    "        if array.ndim == 2:\n",
    "            array = np.repeat(array[:, :, np.newaxis], 3, axis=2)  # go from blackwhite to rgb to make concat work seamless\n",
    "        return array\n",
    "\n",
    "    if len(arrays) > 1:\n",
    "        arrays = [fix_dimensions(array) for array in arrays]\n",
    "        arrays = np.concatenate(arrays, axis=1)\n",
    "\n",
    "    # arrays is just a big 3-dim matrix\n",
    "    im = Image.fromarray(np.uint8(arrays))\n",
    "    im.save(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save(sess, saver, checkpoint_dir, step):\n",
    "    model_name = \"cgan_pix2pix.model\"\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    saver.save(sess, os.path.join(checkpoint_dir, model_name), global_step=step)\n",
    "\n",
    "\n",
    "def sample_model(filenames: [str], epoch: int, sess: tf.Session, source_dir: str, target_dir: str, model: Pix2PixModel,\n",
    "                 sample_dir: str, rng: bool):\n",
    "    batch = None\n",
    "    if rng:\n",
    "        batch = get_image_batch(1, filenames, source_dir, target_dir)\n",
    "    else:\n",
    "        batch = [load_image('ISIC_0000000.jpg', source_dir, target_dir)]\n",
    "\n",
    "    (batch_src, batch_target) = batch[0]\n",
    "    original_source = batch_src.copy()\n",
    "    original_target = batch_target.copy()\n",
    "    batch_src = (batch_src / 255.0 - 0.5) * 2.0  # Transform into range -1, 1\n",
    "    batch_target = (batch_target - 0.5) * 2.0  # Transform into range -1, 1\n",
    "    batch_src = np.array(batch_src).astype(np.float32)[None, :, :, :]\n",
    "    batch_target = np.array(batch_target).astype(np.float32)[None, :, :, None]\n",
    "\n",
    "    sample, d_loss, g_loss = sess.run(\n",
    "        [model.fake_B, model.d_loss, model.g_loss],\n",
    "        feed_dict={model.real_data_source: batch_src,\n",
    "                   model.real_data_target: batch_target}\n",
    "    )\n",
    "\n",
    "    # convert images from [-1,1] to [0,255]\n",
    "    # from shape [1,255,255,1] : tensor to shape [255,255] : nddarray\n",
    "    sample = (tf.squeeze(sample).eval() + 1.0) / 2.0 * 255\n",
    "\n",
    "    save_ndarrays_asimage(os.path.join(sample_dir, 'sample_%d.png' % epoch), original_source, sample,\n",
    "                          original_target * 255)\n",
    "    print(\"[Sample] d_loss: {:.8f}, g_loss: {:.8f}\".format(d_loss, g_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] time: 1.2749, d_loss: 1.36556685, g_loss: 87.52030945\n",
      "Epoch: [ 1] time: 2.1405, d_loss: 1.33267796, g_loss: 84.46889496\n",
      "[Sample] d_loss: 1.36930716, g_loss: 100.65798950\n",
      "Epoch: [ 2] time: 3.3114, d_loss: 1.28457999, g_loss: 79.73972321\n",
      "Epoch: [ 3] time: 8.2926, d_loss: 1.33736110, g_loss: 72.16429901\n",
      "Epoch: [ 4] time: 9.1372, d_loss: 1.56897402, g_loss: 70.81915283\n",
      "Epoch: [ 5] time: 10.1665, d_loss: 3.31513000, g_loss: 63.42492294\n",
      "Epoch: [ 6] time: 11.3621, d_loss: 8.94546700, g_loss: 57.43983078\n",
      "Epoch: [ 7] time: 12.2478, d_loss: 20.60489273, g_loss: 58.34289932\n",
      "Epoch: [ 8] time: 13.1144, d_loss: 41.27815247, g_loss: 53.92530060\n",
      "Epoch: [ 9] time: 13.9831, d_loss: 31.73471069, g_loss: 72.24740601\n",
      "Epoch: [10] time: 15.1940, d_loss: 99.84301758, g_loss: 42.79050064\n",
      "Epoch: [11] time: 16.0716, d_loss: 225.55815125, g_loss: 60.94220734\n",
      "Epoch: [12] time: 16.9933, d_loss: 256.32653809, g_loss: 56.93577957\n",
      "Epoch: [13] time: 17.8959, d_loss: 714.32397461, g_loss: 62.23205185\n",
      "Epoch: [14] time: 18.8126, d_loss: 518.81579590, g_loss: 42.39647293\n",
      "Epoch: [15] time: 19.6832, d_loss: 2134.12695312, g_loss: 37.50886917\n",
      "Epoch: [16] time: 20.5548, d_loss: 3046.95849609, g_loss: 34.73963928\n",
      "Epoch: [17] time: 21.4469, d_loss: 2068.98828125, g_loss: 72.24222565\n",
      "Epoch: [18] time: 22.5067, d_loss: 3253.19409180, g_loss: 37.73980331\n",
      "Epoch: [19] time: 23.5084, d_loss: 4286.23339844, g_loss: 70.56518555\n",
      "Epoch: [20] time: 24.5101, d_loss: 4263.44775391, g_loss: 69.61944580\n",
      "Epoch: [21] time: 25.5778, d_loss: 5316.70019531, g_loss: 53.69157791\n",
      "Epoch: [22] time: 26.4745, d_loss: 2852.11059570, g_loss: 113.83949280\n",
      "Epoch: [23] time: 27.4151, d_loss: 10736.86132812, g_loss: 36.75009155\n",
      "Epoch: [24] time: 28.2851, d_loss: 20511.83398438, g_loss: 31.17498779\n",
      "Epoch: [25] time: 29.2462, d_loss: 13952.69726562, g_loss: 30.80169296\n",
      "Epoch: [26] time: 30.1212, d_loss: 10314.25195312, g_loss: 64.72190857\n",
      "Epoch: [27] time: 31.3491, d_loss: 15587.58300781, g_loss: 41.50351334\n",
      "Epoch: [28] time: 32.2417, d_loss: 30802.72851562, g_loss: 60.98905182\n",
      "Epoch: [29] time: 33.2955, d_loss: 37166.69140625, g_loss: 35.15482712\n",
      "Epoch: [30] time: 34.1961, d_loss: 58470.13281250, g_loss: 26.68567276\n",
      "Epoch: [31] time: 35.2180, d_loss: 47369.78515625, g_loss: 56.02688599\n",
      "Epoch: [32] time: 36.0926, d_loss: 62577.46484375, g_loss: 57.90917969\n",
      "Epoch: [33] time: 36.9932, d_loss: 72347.59375000, g_loss: 24.37432861\n",
      "Epoch: [34] time: 37.9709, d_loss: 97253.96093750, g_loss: 83.31954193\n",
      "Epoch: [35] time: 39.0084, d_loss: 107871.45312500, g_loss: 41.34499359\n",
      "Epoch: [36] time: 40.0322, d_loss: 56059.80078125, g_loss: 29.66301346\n",
      "Epoch: [37] time: 40.9088, d_loss: 61411.95703125, g_loss: 32.08065033\n",
      "Epoch: [38] time: 41.7894, d_loss: 126464.27343750, g_loss: 21.61456108\n",
      "Epoch: [39] time: 42.6603, d_loss: 48084.69921875, g_loss: 26.33058739\n",
      "Epoch: [40] time: 43.6420, d_loss: 104329.71093750, g_loss: 22.47222900\n",
      "Epoch: [41] time: 44.5377, d_loss: 62070.23437500, g_loss: 28.64351273\n",
      "Epoch: [42] time: 45.4103, d_loss: 148541.46875000, g_loss: 49.49777603\n",
      "Epoch: [43] time: 46.4429, d_loss: 71247.63281250, g_loss: 42.85458374\n",
      "Epoch: [44] time: 47.3295, d_loss: 70921.00781250, g_loss: 22.54127312\n",
      "Epoch: [45] time: 48.2792, d_loss: 104544.82812500, g_loss: 23.92667580\n",
      "Epoch: [46] time: 49.2447, d_loss: 103757.29687500, g_loss: 21.35574532\n",
      "Epoch: [47] time: 50.1633, d_loss: 63667.32812500, g_loss: 18.79197121\n",
      "Epoch: [48] time: 51.1010, d_loss: 68690.70312500, g_loss: 55.42733765\n",
      "Epoch: [49] time: 52.0426, d_loss: 63362.23046875, g_loss: 25.52545738\n",
      "Epoch: [50] time: 52.9813, d_loss: 163133.79687500, g_loss: 27.47324181\n",
      "Epoch: [51] time: 53.9163, d_loss: 119809.26562500, g_loss: 94.87751770\n",
      "[Sample] d_loss: 76115.44531250, g_loss: 35.45291519\n",
      "Epoch: [52] time: 55.1497, d_loss: 140520.71875000, g_loss: 20.54465103\n",
      "Epoch: [53] time: 56.0960, d_loss: 111556.31250000, g_loss: 34.08169174\n",
      "Epoch: [54] time: 57.2193, d_loss: 80530.28125000, g_loss: 44.31237793\n",
      "Epoch: [55] time: 58.3425, d_loss: 84428.85156250, g_loss: 38.59676743\n",
      "Epoch: [56] time: 59.3032, d_loss: 105316.42187500, g_loss: 20.99475670\n",
      "Epoch: [57] time: 60.4790, d_loss: 49653.97656250, g_loss: 23.25000191\n",
      "Epoch: [58] time: 61.5786, d_loss: 104908.42187500, g_loss: 19.13597298\n",
      "Epoch: [59] time: 62.8765, d_loss: 90197.68750000, g_loss: 20.92070770\n",
      "Epoch: [60] time: 64.0002, d_loss: 136130.82812500, g_loss: 15.21712875\n",
      "Epoch: [61] time: 64.9919, d_loss: 152818.18750000, g_loss: 13.72467709\n",
      "Epoch: [62] time: 66.1777, d_loss: 76766.92187500, g_loss: 20.21244431\n",
      "Epoch: [63] time: 68.0200, d_loss: 182526.43750000, g_loss: 13.83538723\n",
      "Epoch: [64] time: 69.1809, d_loss: 101814.77343750, g_loss: 13.20438385\n",
      "Epoch: [65] time: 70.2056, d_loss: 120381.46093750, g_loss: 19.87172127\n",
      "Epoch: [66] time: 71.1102, d_loss: 66958.02343750, g_loss: 109.09362030\n",
      "Epoch: [67] time: 72.0059, d_loss: 122643.19531250, g_loss: 52.79963684\n",
      "Epoch: [68] time: 72.9365, d_loss: 127275.49218750, g_loss: 17.50440598\n",
      "Epoch: [69] time: 74.4976, d_loss: 137258.98437500, g_loss: 22.49597549\n",
      "Epoch: [70] time: 75.9757, d_loss: 154899.04687500, g_loss: 28.80681419\n",
      "Epoch: [71] time: 77.1615, d_loss: 266294.12500000, g_loss: 17.76109695\n",
      "Epoch: [72] time: 78.3314, d_loss: 134779.31250000, g_loss: 26.52667236\n",
      "Epoch: [73] time: 79.5808, d_loss: 130857.60937500, g_loss: 27.54259109\n",
      "Epoch: [74] time: 80.6576, d_loss: 154840.34375000, g_loss: 13.95027065\n",
      "Epoch: [75] time: 81.7133, d_loss: 121056.75781250, g_loss: 33.93412781\n",
      "Epoch: [76] time: 82.8401, d_loss: 109653.27343750, g_loss: 16.02709007\n",
      "Epoch: [77] time: 83.7695, d_loss: 212129.54687500, g_loss: 16.42132759\n",
      "Epoch: [78] time: 85.0695, d_loss: 182522.70312500, g_loss: 21.52313805\n",
      "Epoch: [79] time: 85.9841, d_loss: 178350.15625000, g_loss: 12.23886395\n",
      "Epoch: [80] time: 87.0489, d_loss: 217940.21875000, g_loss: 12.00684261\n",
      "Epoch: [81] time: 88.3260, d_loss: 164498.96875000, g_loss: 16.55692673\n",
      "Epoch: [82] time: 89.2206, d_loss: 165872.09375000, g_loss: 19.77871895\n",
      "Epoch: [83] time: 90.1067, d_loss: 149132.43750000, g_loss: 15.63360405\n",
      "Epoch: [84] time: 91.0363, d_loss: 224237.56250000, g_loss: 12.92416477\n",
      "Epoch: [85] time: 92.0140, d_loss: 103632.00781250, g_loss: 50.47518539\n",
      "Epoch: [86] time: 93.2329, d_loss: 182832.28125000, g_loss: 15.73009682\n",
      "Epoch: [87] time: 94.1295, d_loss: 80970.73437500, g_loss: 25.16810226\n",
      "Epoch: [88] time: 95.0126, d_loss: 177833.78125000, g_loss: 127.13332367\n",
      "Epoch: [89] time: 96.0643, d_loss: 107893.45312500, g_loss: 19.28828239\n",
      "Epoch: [90] time: 97.1391, d_loss: 235877.84375000, g_loss: 14.04644203\n",
      "Epoch: [91] time: 98.0297, d_loss: 214011.29687500, g_loss: 27.86275101\n",
      "Epoch: [92] time: 98.9553, d_loss: 90698.01562500, g_loss: 24.95251465\n",
      "Epoch: [93] time: 99.9920, d_loss: 101984.42187500, g_loss: 16.58094215\n",
      "Epoch: [94] time: 101.0438, d_loss: 123615.86718750, g_loss: 53.94729996\n",
      "Epoch: [95] time: 102.2876, d_loss: 174653.54687500, g_loss: 30.41577339\n",
      "Epoch: [96] time: 103.1932, d_loss: 79387.94531250, g_loss: 15.29842472\n",
      "Epoch: [97] time: 104.0839, d_loss: 164014.17187500, g_loss: 95.30463409\n",
      "Epoch: [98] time: 104.9425, d_loss: 150282.62500000, g_loss: 16.74277115\n",
      "Epoch: [99] time: 106.2214, d_loss: 129045.33593750, g_loss: 30.28619576\n",
      "Epoch: [100] time: 107.1050, d_loss: 48677.98828125, g_loss: 45.54140091\n",
      "Epoch: [101] time: 108.0087, d_loss: 139986.78125000, g_loss: 10.76697731\n",
      "[Sample] d_loss: 94682.14062500, g_loss: 30.80150414\n",
      "Epoch: [102] time: 109.1695, d_loss: 248758.75000000, g_loss: 10.98249817\n",
      "Epoch: [103] time: 110.0601, d_loss: 68835.17187500, g_loss: 11.99170876\n",
      "Epoch: [104] time: 110.9287, d_loss: 86000.43750000, g_loss: 123.83023834\n",
      "Epoch: [105] time: 111.7874, d_loss: 143673.15625000, g_loss: 40.85828018\n",
      "Epoch: [106] time: 112.6640, d_loss: 172967.57812500, g_loss: 13.77706814\n",
      "Epoch: [107] time: 113.4916, d_loss: 282945.03125000, g_loss: 22.70234871\n",
      "Epoch: [108] time: 114.3332, d_loss: 247895.37500000, g_loss: 111.23428345\n",
      "Epoch: [109] time: 115.1838, d_loss: 168592.65625000, g_loss: 15.38350773\n",
      "Epoch: [110] time: 116.0324, d_loss: 159285.53125000, g_loss: 11.62661839\n",
      "Epoch: [111] time: 116.9010, d_loss: 277039.87500000, g_loss: 13.77875233\n",
      "Epoch: [112] time: 117.9297, d_loss: 198964.43750000, g_loss: 10.80846119\n",
      "Epoch: [113] time: 118.7863, d_loss: 265616.65625000, g_loss: 9.62869358\n",
      "Epoch: [114] time: 119.6189, d_loss: 227565.96875000, g_loss: 22.09273529\n",
      "Epoch: [115] time: 120.5449, d_loss: 151750.51562500, g_loss: 12.03159809\n",
      "Epoch: [116] time: 121.3905, d_loss: 209878.18750000, g_loss: 11.74473572\n",
      "Epoch: [117] time: 122.2491, d_loss: 184032.20312500, g_loss: 10.90999889\n",
      "Epoch: [118] time: 123.1047, d_loss: 84167.97656250, g_loss: 118.92950439\n",
      "Epoch: [119] time: 123.9704, d_loss: 205337.45312500, g_loss: 12.01094341\n",
      "Epoch: [120] time: 124.8424, d_loss: 238079.54687500, g_loss: 16.04026222\n",
      "Epoch: [121] time: 125.8431, d_loss: 286386.96875000, g_loss: 10.59152031\n",
      "Epoch: [122] time: 126.8478, d_loss: 277902.37500000, g_loss: 8.24519062\n",
      "Epoch: [123] time: 127.8925, d_loss: 221878.62500000, g_loss: 9.96460724\n",
      "Epoch: [124] time: 128.7922, d_loss: 170552.70312500, g_loss: 19.66196632\n",
      "Epoch: [125] time: 129.6788, d_loss: 248718.54687500, g_loss: 10.51506805\n",
      "Epoch: [126] time: 130.7142, d_loss: 243851.12500000, g_loss: 15.69034290\n",
      "Epoch: [127] time: 131.6279, d_loss: 251418.18750000, g_loss: 10.73940659\n",
      "Epoch: [128] time: 132.5255, d_loss: 296044.78125000, g_loss: 8.81983185\n",
      "Epoch: [129] time: 133.4251, d_loss: 252369.64062500, g_loss: 8.93021488\n",
      "Epoch: [130] time: 134.4887, d_loss: 248781.39062500, g_loss: 8.61735630\n",
      "Epoch: [131] time: 135.4003, d_loss: 251470.23437500, g_loss: 105.66355133\n",
      "Epoch: [132] time: 136.2870, d_loss: 165205.76562500, g_loss: 21.42754745\n",
      "Epoch: [133] time: 137.1736, d_loss: 166449.12500000, g_loss: 35.81809235\n",
      "Epoch: [134] time: 138.2313, d_loss: 203771.62500000, g_loss: 47.72694397\n",
      "Epoch: [135] time: 139.1409, d_loss: 176972.76562500, g_loss: 18.25510788\n",
      "Epoch: [136] time: 140.0265, d_loss: 187561.96875000, g_loss: 12.00799751\n",
      "Epoch: [137] time: 140.9112, d_loss: 128286.02343750, g_loss: 16.72989845\n",
      "Epoch: [138] time: 141.8208, d_loss: 302731.65625000, g_loss: 29.16341782\n",
      "Epoch: [139] time: 142.8105, d_loss: 260679.79687500, g_loss: 14.66826534\n",
      "Epoch: [140] time: 143.7172, d_loss: 390636.65625000, g_loss: 8.15752983\n",
      "Epoch: [141] time: 144.6198, d_loss: 402780.65625000, g_loss: 8.09256172\n",
      "Epoch: [142] time: 145.5504, d_loss: 282938.00000000, g_loss: 20.65399933\n",
      "Epoch: [143] time: 146.6702, d_loss: 216069.90625000, g_loss: 9.77137947\n",
      "Epoch: [144] time: 147.6699, d_loss: 272824.34375000, g_loss: 13.70067596\n",
      "Epoch: [145] time: 148.5596, d_loss: 184377.39062500, g_loss: 15.84541225\n",
      "Epoch: [146] time: 149.4642, d_loss: 290075.18750000, g_loss: 7.99637890\n",
      "Epoch: [147] time: 150.4066, d_loss: 198535.64062500, g_loss: 9.14399624\n",
      "Epoch: [148] time: 151.3732, d_loss: 216563.10937500, g_loss: 14.71754265\n",
      "Epoch: [149] time: 152.3078, d_loss: 355445.00000000, g_loss: 7.12961388\n",
      "Epoch: [150] time: 153.3055, d_loss: 156478.68750000, g_loss: 32.09558868\n",
      "Epoch: [151] time: 154.3753, d_loss: 195406.23437500, g_loss: 18.37717819\n",
      "[Sample] d_loss: 152042.50000000, g_loss: 20.57111931\n",
      "Epoch: [152] time: 156.0865, d_loss: 246735.84375000, g_loss: 8.72066498\n",
      "Epoch: [153] time: 157.6246, d_loss: 184196.40625000, g_loss: 11.65461540\n",
      "Epoch: [154] time: 158.7294, d_loss: 193131.50000000, g_loss: 84.95606232\n",
      "Epoch: [155] time: 159.7241, d_loss: 229181.25000000, g_loss: 24.04528236\n",
      "Epoch: [156] time: 160.6908, d_loss: 331608.25000000, g_loss: 18.98663330\n",
      "Epoch: [157] time: 161.7565, d_loss: 271632.00000000, g_loss: 11.93716526\n",
      "Epoch: [158] time: 162.7913, d_loss: 208505.78125000, g_loss: 7.68525505\n",
      "Epoch: [159] time: 163.8254, d_loss: 98531.06250000, g_loss: 84.02606201\n",
      "Epoch: [160] time: 164.7830, d_loss: 70851.55468750, g_loss: 40.28234482\n",
      "Epoch: [161] time: 166.7774, d_loss: 222344.48437500, g_loss: 18.95299530\n",
      "Epoch: [162] time: 167.7682, d_loss: 220076.89062500, g_loss: 10.64943790\n",
      "Epoch: [163] time: 168.8139, d_loss: 187177.17187500, g_loss: 23.86837959\n",
      "Epoch: [164] time: 169.8046, d_loss: 95503.45312500, g_loss: 21.75035858\n",
      "Epoch: [165] time: 170.8573, d_loss: 360599.93750000, g_loss: 15.75556850\n",
      "Epoch: [166] time: 171.9902, d_loss: 218166.26562500, g_loss: 18.50410080\n",
      "Epoch: [167] time: 172.9708, d_loss: 172548.04687500, g_loss: 14.70835781\n",
      "Epoch: [168] time: 174.0866, d_loss: 208653.06250000, g_loss: 16.19380760\n",
      "Epoch: [169] time: 175.0863, d_loss: 211412.40625000, g_loss: 20.58942986\n",
      "Epoch: [170] time: 176.0600, d_loss: 146134.00000000, g_loss: 34.71864700\n",
      "Epoch: [171] time: 177.0753, d_loss: 199460.54687500, g_loss: 24.91934586\n",
      "Epoch: [172] time: 178.1510, d_loss: 201019.48437500, g_loss: 12.34636497\n",
      "Epoch: [173] time: 179.2852, d_loss: 307147.46875000, g_loss: 15.12002182\n",
      "Epoch: [174] time: 180.2379, d_loss: 206304.29687500, g_loss: 6.55807638\n",
      "Epoch: [175] time: 181.5658, d_loss: 230909.34375000, g_loss: 37.76512909\n",
      "Epoch: [176] time: 182.5584, d_loss: 95848.96093750, g_loss: 26.72646332\n",
      "Epoch: [177] time: 183.5161, d_loss: 221857.43750000, g_loss: 13.65368176\n",
      "Epoch: [178] time: 184.4917, d_loss: 154208.40625000, g_loss: 17.24988747\n",
      "Epoch: [179] time: 185.5855, d_loss: 425156.46875000, g_loss: 8.53139973\n",
      "Epoch: [180] time: 186.6363, d_loss: 277516.71875000, g_loss: 9.14096642\n",
      "Epoch: [181] time: 187.6518, d_loss: 182378.45312500, g_loss: 8.85066319\n",
      "Epoch: [182] time: 188.9877, d_loss: 234599.23437500, g_loss: 13.90101624\n",
      "Epoch: [183] time: 190.0005, d_loss: 343377.93750000, g_loss: 7.42597294\n",
      "Epoch: [184] time: 191.0652, d_loss: 286129.46875000, g_loss: 13.74438000\n",
      "Epoch: [185] time: 192.3121, d_loss: 132676.40625000, g_loss: 10.03425312\n",
      "Epoch: [186] time: 193.6180, d_loss: 241101.43750000, g_loss: 21.40887833\n",
      "Epoch: [187] time: 194.8769, d_loss: 399941.71875000, g_loss: 9.20088768\n",
      "Epoch: [188] time: 196.0097, d_loss: 244520.56250000, g_loss: 9.98152924\n",
      "Epoch: [189] time: 197.0495, d_loss: 267395.28125000, g_loss: 11.04419041\n",
      "Epoch: [190] time: 198.3254, d_loss: 274156.18750000, g_loss: 11.34136009\n",
      "Epoch: [191] time: 199.5402, d_loss: 181484.43750000, g_loss: 41.18349075\n",
      "Epoch: [192] time: 200.6670, d_loss: 198626.20312500, g_loss: 56.62582016\n",
      "Epoch: [193] time: 201.6638, d_loss: 240589.75000000, g_loss: 10.09365177\n",
      "Epoch: [194] time: 202.6484, d_loss: 154872.26562500, g_loss: 28.56828308\n",
      "Epoch: [195] time: 203.6852, d_loss: 358215.00000000, g_loss: 7.86779499\n",
      "Epoch: [196] time: 204.8890, d_loss: 189591.76562500, g_loss: 14.28870964\n",
      "Epoch: [197] time: 205.9378, d_loss: 249532.23437500, g_loss: 10.51465797\n",
      "Epoch: [198] time: 206.9735, d_loss: 233208.25000000, g_loss: 118.62843323\n",
      "Epoch: [199] time: 208.0543, d_loss: 200595.90625000, g_loss: 9.21730614\n",
      "Epoch: [200] time: 209.2351, d_loss: 216623.00000000, g_loss: 9.95396423\n",
      "Epoch: [201] time: 210.2879, d_loss: 148935.32812500, g_loss: 130.83653259\n",
      "[Sample] d_loss: 177979.25000000, g_loss: 17.62268448\n",
      "Epoch: [202] time: 211.6578, d_loss: 126407.82812500, g_loss: 51.83497620\n",
      "Epoch: [203] time: 212.7907, d_loss: 337389.87500000, g_loss: 11.19711971\n",
      "Epoch: [204] time: 213.7934, d_loss: 432272.68750000, g_loss: 9.37101746\n",
      "Epoch: [205] time: 214.9222, d_loss: 238457.59375000, g_loss: 24.46442604\n",
      "Epoch: [206] time: 215.9405, d_loss: 326300.21875000, g_loss: 20.77121925\n",
      "Epoch: [207] time: 216.9712, d_loss: 352584.12500000, g_loss: 8.94698048\n",
      "Epoch: [208] time: 218.0490, d_loss: 282852.90625000, g_loss: 34.78392410\n",
      "Epoch: [209] time: 219.1047, d_loss: 526590.31250000, g_loss: 9.45166492\n",
      "Epoch: [210] time: 220.1515, d_loss: 408224.43750000, g_loss: 11.42053509\n",
      "Epoch: [211] time: 221.2483, d_loss: 222677.32812500, g_loss: 14.44380093\n",
      "Epoch: [212] time: 222.2880, d_loss: 127845.42968750, g_loss: 80.21233368\n",
      "Epoch: [213] time: 223.4808, d_loss: 311263.71875000, g_loss: 29.61471748\n",
      "Epoch: [214] time: 224.7297, d_loss: 458097.71875000, g_loss: 15.69562244\n"
     ]
    }
   ],
   "source": [
    "source_dir = r'../../../pix2pix-poc-data/training/source'\n",
    "target_dir = r'../../../pix2pix-poc-data/training/target'\n",
    "sourcefiles = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "sample_dir = \"./samples/sample-%d-%d-%d--%02d%02d\" % (\n",
    "    now.day, now.month, now.year, now.hour, now.minute)  # Generated samples\n",
    "checkpoint_dir = \"./checkpoints\"  # Model\n",
    "if not os.path.exists('./samples'):\n",
    "    os.mkdir('./samples')\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.mkdir(sample_dir)\n",
    "\n",
    "use_random_image_as_sample = False\n",
    "batch_size = 1\n",
    "size = IMAGE_SIZE\n",
    "num_feature_maps = 64\n",
    "is_grayscale = False\n",
    "\n",
    "restore_iteration = None\n",
    "iterations = 50000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model = Pix2PixModel(batch_size=batch_size, image_size=size, src_color_channels=3, target_color_channels=1)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    if restore_iteration is not None and restore_iteration > 0:\n",
    "        iteration_start = restore_iteration + 1\n",
    "        checkpoint = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        checkpoint_name = os.path.basename(checkpoint.model_checkpoint_path)\n",
    "        print('checkpoint_name=' + str(checkpoint_name))\n",
    "        saver.restore(sess, os.path.join(checkpoint_dir, checkpoint_name))\n",
    "    else:\n",
    "        iteration_start = 0\n",
    "\n",
    "    # Optimizers\n",
    "    disc_optim = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5)  # TODO: pix2pix params\n",
    "    gen_optim = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5)  # TODO: pix2pix params\n",
    "\n",
    "    disc_update_step = disc_optim.minimize(model.glsloss, var_list=model.d_vars)\n",
    "    gen_update_step = gen_optim.minimize(model.g_loss, var_list=model.g_vars)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # logging\n",
    "    writer = tf.summary.FileWriter(\"./logs\", sess.graph)\n",
    "    g_sum = tf.summary.merge([model.d__sum,\n",
    "                              model.fake_B_sum, model.d_loss_fake_sum, model.g_loss_sum])\n",
    "    d_sum = tf.summary.merge([model.d_sum, model.d_loss_real_sum, model.d_loss_sum])\n",
    "\n",
    "    start_time = time.time()\n",
    "    for iteration in range(iteration_start, iterations):\n",
    "        batch = get_image_batch(batch_size, sourcefiles,\n",
    "                                source_dir=source_dir,\n",
    "                                target_dir=target_dir)\n",
    "        (batch_src, batch_target) = batch[0]\n",
    "        batch_src = (batch_src / 255.0 - 0.5) * 2.0  # Transform into range -1, 1\n",
    "        batch_target = (batch_target - 0.5) * 2.0  # Transform into range -1, 1\n",
    "\n",
    "        batch_src = np.array(batch_src).astype(np.float32)[None, :, :, :]\n",
    "        batch_target = np.array(batch_target).astype(np.float32)[None, :, :, None]\n",
    "\n",
    "        _, summary_str = sess.run([disc_update_step, d_sum],\n",
    "                                  feed_dict={model.real_data_source: batch_src,\n",
    "                                             model.real_data_target: batch_target})\n",
    "\n",
    "        writer.add_summary(summary_str, iteration)\n",
    "\n",
    "        # Update G network twice\n",
    "        _, summary_str = sess.run([gen_update_step, g_sum],\n",
    "                                  feed_dict={model.real_data_source: batch_src,\n",
    "                                             model.real_data_target: batch_target})\n",
    "        writer.add_summary(summary_str, iteration)\n",
    "        #_, summary_str = sess.run([gen_update_step, g_sum],\n",
    "                                  #feed_dict={model.real_data_source: batch_src,\n",
    "                                            # model.real_data_target: batch_target})\n",
    "        #writer.add_summary(summary_str, iteration)\n",
    "\n",
    "        errD_fake = model.d_loss_fake.eval(\n",
    "            {model.real_data_target: batch_target, model.real_data_source: batch_src})\n",
    "        errD_real = model.d_loss_real.eval(\n",
    "            {model.real_data_target: batch_target, model.real_data_source: batch_src})\n",
    "        errG = model.g_loss.eval({model.real_data_target: batch_target, model.real_data_source: batch_src})\n",
    "\n",
    "        print(\"Epoch: [%2d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n",
    "              % (iteration, time.time() - start_time, errD_fake + errD_real, errG))\n",
    "\n",
    "        if iteration % 50 == 1:\n",
    "            # gib nice picture output :)\n",
    "            sample_model(sourcefiles, iteration, sess, source_dir, target_dir, model, sample_dir,\n",
    "                         use_random_image_as_sample)\n",
    "\n",
    "        if iteration % 500 == 2:\n",
    "            save(sess, saver, checkpoint_dir, iteration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python",
   "language": "python",
   "name": ".python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
