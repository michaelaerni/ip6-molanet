{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "sys.path.append(os.path.abspath(\"../..\"))\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "from molanet.models.glsgan import GlsGANModel\n",
    "from molanet.models.glsgan import IMAGE_SIZE\n",
    "import molanet.operations as ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(name: str, source_dir, target_dir, size=IMAGE_SIZE):\n",
    "    def transformImageNameSource(name):\n",
    "        return os.path.join(source_dir, name)\n",
    "\n",
    "    def transformImageNameTarget(name: str):\n",
    "        name = name.replace('.jpg', '_Segmentation.png')\n",
    "        return os.path.join(target_dir, name)\n",
    "\n",
    "    source_image = Image.open(transformImageNameSource(name))\n",
    "    target_image = Image.open(transformImageNameTarget(name))\n",
    "\n",
    "    # TODO think about proper resizing... is dis hacky? I don't know\n",
    "    size = size, size\n",
    "    source = source_image.resize(size, Image.BICUBIC)\n",
    "    target = target_image.resize(size, Image.NEAREST)\n",
    "    target = target.convert('1')  # to black and white\n",
    "\n",
    "    return np.array(source).astype(np.float32), np.array(target).astype(np.float32)\n",
    "\n",
    "\n",
    "def get_image_batch(batch_size, source_file_names, source_dir, target_dir) -> [np.ndarray, np.ndarray]:\n",
    "    # TODO chances are we don't get fucked by rng\n",
    "    indices = [random.randint(0, len(source_file_names) - 1) for _ in range(batch_size)]\n",
    "    images = [load_image(source_file_names[i], source_dir, target_dir) for i in indices]\n",
    "    return images\n",
    "\n",
    "def transform_batch(image_batch):\n",
    "    batch_src, batch_target = image_batch[0]\n",
    "    batch_src = (batch_src / 255.0 - 0.5) * 2.0  # Transform into range -1, 1\n",
    "    batch_target = (batch_target - 0.5) * 2.0  # Transform into range -1, 1\n",
    "\n",
    "    batch_src = np.array(batch_src).astype(np.float32)[None, :, :, :]\n",
    "    batch_target = np.array(batch_target).astype(np.float32)[None, :, :, None]\n",
    "    \n",
    "    if(len(image_batch) > 1):\n",
    "        iterimages = iter(image_batch)\n",
    "        next(iterimages) #skip first\n",
    "        for src, target in iterimages:\n",
    "            src = (src / 255.0 - 0.5) * 2.0  # Transform into range -1, 1\n",
    "            target = (target - 0.5) * 2.0  # Transform into range -1, 1\n",
    "            src =np.array(src).astype(np.float32)[None,:, :, :]\n",
    "            target = np.array(target).astype(np.float32)[None,:, :, None]\n",
    "            batch_src = np.concatenate([batch_src,src],axis=0)\n",
    "            batch_target = np.concatenate([batch_target,target],axis=0)\n",
    "    return batch_src, batch_target\n",
    "\n",
    "def save_ndarrays_asimage(filename: str, *arrays: np.ndarray):\n",
    "    def fix_dimensions(array):\n",
    "        if array.ndim > 3 or array.ndim < 2: raise ValueError('arrays must have 2 or 3 dimensions')\n",
    "        if array.ndim == 2:\n",
    "            array = np.repeat(array[:, :, np.newaxis], 3, axis=2)  # go from blackwhite to rgb to make concat work seamless\n",
    "        return array\n",
    "\n",
    "    if len(arrays) > 1:\n",
    "        arrays = [fix_dimensions(array) for array in arrays]\n",
    "        arrays = np.concatenate(arrays, axis=1)\n",
    "\n",
    "    # arrays is just a big 3-dim matrix\n",
    "    im = Image.fromarray(np.uint8(arrays))\n",
    "    im.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(sess, saver, checkpoint_dir, step):\n",
    "    model_name = \"glsgan.model\"\n",
    "\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "\n",
    "    saver.save(sess, os.path.join(checkpoint_dir, model_name), global_step=step)\n",
    "\n",
    "\n",
    "def sample_model(filenames: [str], batch_size: int,epoch: int, sess: tf.Session, source_dir: str, target_dir: str, model: GlsGANModel,\n",
    "                 sample_dir: str, max_samples:int=3):\n",
    "    nsamples = min(batch_size, max_samples)\n",
    "\n",
    "    batch = get_image_batch(batch_size, filenames, source_dir, target_dir)    \n",
    "    batch_src, batch_target = transform_batch(batch)\n",
    "   \n",
    "    sample, d_loss, g_loss = sess.run(\n",
    "        [model.fake_B, model.d_loss, model.g_loss],\n",
    "        feed_dict={model.real_data_source: batch_src,\n",
    "                   model.real_data_target: batch_target}\n",
    "    )\n",
    "    \n",
    "    size = sample.shape[2]\n",
    "    zdim = batch_src.shape[-1]\n",
    "    \n",
    "    sample = tf.squeeze(sample).eval()[:nsamples]\n",
    "    batch_src = batch_src[:nsamples]\n",
    "    batch_target = batch_target[:nsamples]\n",
    "    # from shape [nsamples,size,size,1] : tf.tensor to shape [size*nsamples,size] : ndarray\n",
    "    sample = (np.reshape(sample,[size*nsamples,size]) + 1.0) / 2.0 * 255\n",
    "    original_source = (tf.reshape(batch_src,[size*nsamples,size,zdim]).eval() + 1.0) / 2.0 * 255\n",
    "    original_target = (tf.reshape(tf.squeeze(batch_target),[size*nsamples,size]).eval() + 1.0) / 2.0 * 255\n",
    "\n",
    "    save_ndarrays_asimage(os.path.join(sample_dir, 'sample_%d.png' % epoch), original_source, sample,\n",
    "                          original_target)\n",
    "    print(\"[Sample] d_loss: {:.8f}, g_loss: {:.8f}\".format(d_loss, g_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [ 0] time: 3.4334, d_loss: 1.37309682, g_loss: 79.05183411\n",
      "[Sample] d_loss: 1.38929558, g_loss: 88.12082672\n",
      "Epoch: [ 1] time: 7.3603, d_loss: 1.47140992, g_loss: 82.87152863\n",
      "Epoch: [ 2] time: 10.3894, d_loss: 1.73259103, g_loss: 80.03784943\n",
      "Epoch: [ 3] time: 19.1286, d_loss: 2.71475410, g_loss: 69.73803711\n",
      "Epoch: [ 4] time: 22.2669, d_loss: 4.20955849, g_loss: 64.98880005\n",
      "Epoch: [ 5] time: 25.5642, d_loss: 10.98469067, g_loss: 57.46200943\n",
      "Epoch: [ 6] time: 28.8495, d_loss: 21.55561066, g_loss: 51.13998795\n",
      "Epoch: [ 7] time: 32.2390, d_loss: 42.87924194, g_loss: 75.87000275\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-236aa10d3523>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     94\u001b[0m         errD_real = model.d_loss_real.eval(\n\u001b[0;32m     95\u001b[0m             {model.real_data_target: batch_target, model.real_data_source: batch_src})\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0merrG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal_data_target\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreal_data_source\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_src\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch: [%2d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\"\u001b[0m               \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrD_fake\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0merrD_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m     \"\"\"\n\u001b[1;32m--> 567\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3727\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3728\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3729\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\pdcwi\\Documents\\IP6 nonsynced\\ip6-molanet\\.python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "source_dir = r'../../../pix2pix-poc-data/training/source'\n",
    "target_dir = r'../../../pix2pix-poc-data/training/target'\n",
    "sourcefiles = [f for f in os.listdir(source_dir) if os.path.isfile(os.path.join(source_dir, f))]\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "sample_dir = \"./samples/sample-%d-%d-%d--%02d%02d\" % (\n",
    "    now.day, now.month, now.year, now.hour, now.minute)  # Generated samples\n",
    "checkpoint_dir = \"./checkpoints\"  # Model\n",
    "if not os.path.exists('./samples'):\n",
    "    os.mkdir('./samples')\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.mkdir(sample_dir)\n",
    "\n",
    "batch_size = 5\n",
    "size = IMAGE_SIZE\n",
    "num_feature_maps = 64\n",
    "is_grayscale = False\n",
    "L1_lambda = 100\n",
    "glsgan_alpha = 0 # ls-gan\n",
    "iterations = 50000\n",
    "N = 1\n",
    "\n",
    "restore_iteration = None\n",
    "use_random_image_as_sample = True\n",
    "max_samples = 5\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model = GlsGANModel(batch_size=batch_size, image_size=size, src_color_channels=3, target_color_channels=1,l1_lambda=L1_lambda)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    if restore_iteration is not None and restore_iteration > 0:\n",
    "        iration_start = restore_iteration + 1\n",
    "        checkpoint = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        checkpoint_name = os.path.basename(checkpoint.model_checkpoint_path)\n",
    "        print('checkpoint_name=' + str(checkpoint_name))\n",
    "        saver.restore(sess, os.path.join(checkpoint_dir, checkpoint_name))\n",
    "    else:\n",
    "        iteration_start = 0\n",
    "        \n",
    "    #make glsgan\n",
    "    #see glsgan paper and https://github.com/guojunq/glsgan/blob/master/glsgan.lua#L257\n",
    "    def l1diff(x,y):\n",
    "        dist = tf.reduce_sum(tf.abs(tf.round(y)-tf.round(x)))\n",
    "        return dist\n",
    "    pdist = L1_lambda * l1diff(model.real_B,model.fake_B)\n",
    "    cost1 = pdist + model.d_loss_real - model.d_loss_fake\n",
    "\n",
    "    glsloss =ops.leaky_relu(cost1,glsgan_alpha)\n",
    "    #self.d_error_hinge = tf.reduce_mean(self.glsloss)\n",
    "\n",
    "    # Optimizers\n",
    "    disc_optim = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5)  # TODO: pix2pix params\n",
    "    gen_optim = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5)  # TODO: pix2pix params\n",
    "\n",
    "    disc_update_step = disc_optim.minimize(glsloss, var_list=model.d_vars)\n",
    "    gen_update_step = gen_optim.minimize(model.g_loss, var_list=model.g_vars)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # logging\n",
    "    writer = tf.summary.FileWriter(\"./logs\", sess.graph)\n",
    "    g_sum = tf.summary.merge([model.d__sum,\n",
    "                              model.fake_B_sum, model.d_loss_fake_sum, model.g_loss_sum])\n",
    "    d_sum = tf.summary.merge([model.d_sum, model.d_loss_real_sum, model.d_loss_sum])\n",
    "\n",
    "    start_time = time.time()\n",
    "    for iteration in range(iteration_start, iterations):\n",
    "        batch = get_image_batch(batch_size, sourcefiles,\n",
    "                                source_dir=source_dir,\n",
    "                                target_dir=target_dir)\n",
    "        batch_src,batch_target = transform_batch(batch)\n",
    "\n",
    "        #as proposed in glsgan paper update discriminator N time every iteration\n",
    "        for i in range(0,N):\n",
    "            _, summary_str = sess.run([disc_update_step, d_sum],\n",
    "                                      feed_dict={model.real_data_source: batch_src,\n",
    "                                                 model.real_data_target: batch_target})\n",
    "\n",
    "            writer.add_summary(summary_str, iteration)\n",
    "\n",
    "        # Update G network\n",
    "        _, summary_str = sess.run([gen_update_step, g_sum],\n",
    "                                  feed_dict={model.real_data_source: batch_src,\n",
    "                                             model.real_data_target: batch_target})\n",
    "        writer.add_summary(summary_str, iteration)\n",
    "        #_, summary_str = sess.run([gen_update_step, g_sum],\n",
    "                                  #feed_dict={model.real_data_source: batch_src,\n",
    "                                            # model.real_data_target: batch_target})\n",
    "        #writer.add_summary(summary_str, iteration)\n",
    "\n",
    "        errD_fake = model.d_loss_fake.eval(\n",
    "            {model.real_data_target: batch_target, model.real_data_source: batch_src})\n",
    "        errD_real = model.d_loss_real.eval(\n",
    "            {model.real_data_target: batch_target, model.real_data_source: batch_src})\n",
    "        errG = model.g_loss.eval({model.real_data_target: batch_target, model.real_data_source: batch_src})\n",
    "\n",
    "        print(\"Epoch: [%2d] time: %4.4f, d_loss: %.8f, g_loss: %.8f\" \\\n",
    "              % (iteration, time.time() - start_time, errD_fake + errD_real, errG))\n",
    "\n",
    "        if iteration % 50 == 1:\n",
    "            # gib nice picture output :)\n",
    "            sample_model(sourcefiles, batch_size, iteration, sess, source_dir, target_dir, model, sample_dir)\n",
    "\n",
    "        if iteration % 500 == 2:\n",
    "            save(sess, saver, checkpoint_dir, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".python",
   "language": "python",
   "name": ".python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
